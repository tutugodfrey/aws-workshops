import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from awsglue.dynamicframe import DynamicFrameCollection
from awsglue.dynamicframe import DynamicFrame
from awsglueml.transforms import FillMissingValues

# Script generated for node Custom Transform
def MyTransform(glueContext, dfc) -> DynamicFrameCollection:
    # new dataframe from collection
    new_dynf = dfc.select(list(dfc.keys())[1])
    old_dynf = dfc.select(list(dfc.keys())[0])

    # convert dynamicframe to dataframe
    new_df = new_dynf.toDF()
    old_df = old_dynf.toDF()

    # print rows of new and old dataframes
    print("new dataframe")
    new_df.show(n=5, vertical=True, truncate=50)
    print("old dataframe")
    old_df.show(n=5, vertical=True, truncate=50)

    if old_df.count() == 0:
        update_df = new_df
    else:
        # only keep the new_df data that is not the same as the old df_data
        update_df = new_df.join(old_df, [new_df.rank == old_df.rank], how="left_anti")

    # print unique rows from new data
    print("unique rows")
    update_df.show(n=5, vertical=True, truncate=50)

    # convert changed dataframe to dynamic dataframe
    update_dynf = DynamicFrame.fromDF(update_df, glueContext, "changed")

    # return new dynamicframe collection with only the new results
    return DynamicFrameCollection({"update_dynf": update_dynf}, glueContext)


args = getResolvedOptions(sys.argv, ["JOB_NAME"])
sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args["JOB_NAME"], args)

# Script generated for node S3 bucket
S3_bucket_node_1 = glueContext.create_dynamic_frame.from_options(
    format_options={
        "quoteChar": '"',
        "withHeader": True,
        "separator": ",",
        "optimizePerformance": False,
    },
    connection_type="s3",
    format="csv",
    connection_options={
        "paths": [
            "s3://databucket-us-east-1-7402903098499768/data/movies_csv/movies.csv"
        ],
        "recurse": True,
    },
    transformation_ctx="S3_bucket_node_1",
)

# Script generated for node Amazon S3
Amazon_S3_node_2 = glueContext.create_dynamic_frame.from_catalog(
    database="transform-movies-db",
    table_name="movies",
    transformation_ctx="Amazon_S3_node_2",
)

# Script generated for node Fill Missing Values
Fill_Missing_Values_node_3 = FillMissingValues.apply(
    frame=S3_bucket_node_1,
    missing_values_column="rating",
    transformation_ctx="Fill_Missing_Values_node_3",
)

# Script generated for node Change Schema Apply Mapping
Change_Schema_Apply_Mapping_node_4 = ApplyMapping.apply(
    frame=Amazon_S3_node_2,
    mappings=[
        ("year", "long", "year", "bigint"),
        ("title", "string", "title", "string"),
        ("directors_0", "string", "directors_0", "string"),
        ("genres_0", "string", "genres_0", "string"),
        ("genres_1", "string", "genres_1", "string"),
        ("rank", "long", "rank", "bigint"),
        ("running_time_secs", "long", "running_time_secs", "bigint"),
        ("actors_0", "string", "actors_0", "string"),
        ("actors_1", "string", "actors_1", "string"),
        ("actors_2", "string", "actors_2", "string"),
        ("directors_1", "string", "directors_1", "string"),
        ("directors_2", "string", "directors_2", "string"),
        ("rating_filled", "double", "rating_filled", "double"),
    ],
    transformation_ctx="Change_Schema_Apply_Mapping_node_4",
)

# Script generated for node Change Schema Apply Mapping
Change_Schema_Apply_Mapping_node_5 = ApplyMapping.apply(
    frame=Fill_Missing_Values_node_3,
    mappings=[
        ("year", "string", "year", "bigint"),
        ("title", "string", "title", "string"),
        ("directors_0", "string", "directors_0", "string"),
        ("genres_0", "string", "genres_0", "string"),
        ("genres_1", "string", "genres_1", "string"),
        ("rank", "string", "rank", "bigint"),
        ("running_time_secs", "string", "running_time_secs", "bigint"),
        ("actors_0", "string", "actors_0", "string"),
        ("actors_1", "string", "actors_1", "string"),
        ("actors_2", "string", "actors_2", "string"),
        ("directors_1", "string", "directors_1", "string"),
        ("directors_2", "string", "directors_2", "string"),
        ("rating_filled", "string", "rating_filled", "double"),
    ],
    transformation_ctx="Change_Schema_Apply_Mapping_node_5",
)

# Script generated for node Custom Transform
CustomTransform_node_6 = MyTransform(
    glueContext,
    DynamicFrameCollection(
        {
            "Change_Schema_Apply_Mapping_node_4": Change_Schema_Apply_Mapping_node_4,
            "Change_Schema_Apply_Mapping_node_5": Change_Schema_Apply_Mapping_node_5,
        },
        glueContext,
    ),
)

# Script generated for node Select From Collection
SelectFromCollection_node_7 = SelectFromCollection.apply(
    dfc=CustomTransform_node_6,
    key=list(CustomTransform_node_6.keys())[0],
    transformation_ctx="SelectFromCollection_node_7",
)

# Script generated for node AWS Glue Data Catalog
AWSGlueDataCatalog_node_8 = glueContext.write_dynamic_frame.from_catalog(
    frame=SelectFromCollection_node_7,
    database="transform-movies-db",
    table_name="movies",
    transformation_ctx="AWSGlueDataCatalog_node_8",
)

job.commit()
